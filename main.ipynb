{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import time\n",
    "import geojson\n",
    "import requests\n",
    "import geopandas\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Скачивание датасета \"места общественного питания в городе Москва\" при помощи API request с сайта data.mos.ru"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_all_data_by_API():\n",
    "    data_clean = []\n",
    "    url_count = 'https://apidata.mos.ru/v1/datasets/1903/count'\n",
    "    params_count = {\n",
    "        'api_key': '2142785399b8838f0312c6cd35ddc39b'\n",
    "    }\n",
    "    resp = requests.get(url=url_count, params=params_count)\n",
    "    count = resp.text\n",
    "    time.sleep(1)\n",
    "\n",
    "    url_rows = 'https://apidata.mos.ru/v1/datasets/1903/rows'\n",
    "    for i in range(0, int(count), 500):\n",
    "        print(i)\n",
    "        # skip = 0 if i == 500 else 500\n",
    "        params = {\n",
    "            'api_key': '2142785399b8838f0312c6cd35ddc39b',\n",
    "            '$orderby': 'global_id',\n",
    "            '$top': 500,\n",
    "            '$skip': i\n",
    "        }\n",
    "        time.sleep(3)\n",
    "        resp_rows = requests.get(url=url_rows, params=params)\n",
    "        print(resp_rows)\n",
    "        if (resp_rows.status_code == 200):\n",
    "            data = resp_rows.json()\n",
    "\n",
    "            def prepare_dict(response_item):\n",
    "                temp = {\n",
    "                    'Name': response_item['Cells']['Name'],\n",
    "                    'IsNetObject': response_item['Cells']['IsNetObject'],\n",
    "                    'OperatingCompany': response_item['Cells']['OperatingCompany'],\n",
    "                    'AdmArea': response_item['Cells']['AdmArea'],\n",
    "                    'District': response_item['Cells']['District'],\n",
    "                    'Address': response_item['Cells']['Address'],\n",
    "                    'PublicPhone': response_item['Cells']['PublicPhone'][0]['PublicPhone'] if response_item['Cells']['PublicPhone'][0]['PublicPhone'] != \"\" else \"\",\n",
    "                    'SeatsCount': response_item['Cells']['SeatsCount'],\n",
    "                    'SocialPrivileges': response_item['Cells']['SocialPrivileges'],\n",
    "                    'Latitude' : response_item['Cells']['geoData']['coordinates'][1],\n",
    "                    'Longitude' : response_item['Cells']['geoData']['coordinates'][0],\n",
    "                }                \n",
    "                return temp\n",
    "\n",
    "            data_clean.extend([prepare_dict(item) for item in data if not isinstance(item, str)])\n",
    "            print('legnth = ', len(data_clean))\n",
    "\n",
    "    df = pd.DataFrame(data_clean)\n",
    "    df.insert(loc=0, column='Number', value=range(1, len(df) + 1))\n",
    "    return df, count\n",
    "\n",
    "df, count = get_all_data_by_API()\n",
    "print(df.count())\n",
    "\n",
    "# записываем результат в csv\n",
    "df.to_csv('./eating.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('./eating.csv')\n",
    "df.drop(columns=['Unnamed: 0'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['IsNetObject'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['AdmArea'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['District'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfg=df[df['IsNetObject'] == 'нет'].groupby('AdmArea').count().reset_index()\n",
    "dfg"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Добавляем колонку рейтинга с дефолтным значением -1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_search_google = df\n",
    "df_search_google.insert(df_search_google.shape[1], 'Rating', -1)\n",
    "df_search_google[\"Address\"] = df_search_google[\"Address\"].str.replace('Российская Федерация,', '').str.strip()\n",
    "df_search_google['Address'] = df_search_google['Address'].apply(lambda x: (\",\").join(list(filter(lambda y: 'муниципальный округ' not in y, x.split(',')))))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Отправляем запросы с названием заведения и его адресом гуглу и парсим возвращаемый результат \"оценка заведения\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for index, row in df_search_google.iterrows():\n",
    "    if 'школа' not in df_search_google.at[index, 'Name'].lower():\n",
    "        search_place = row['Name'] + ' ' + row['Address']\n",
    "        with requests.Session() as s:\n",
    "            url = f\"https://www.google.com/search?\"\n",
    "            headers = {\n",
    "                \"referer\":\"referer: https://www.google.com/\",\n",
    "                \"user-agent\":\"Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/89.0.4389.114 Safari/537.36\",\n",
    "            }\n",
    "            params = {\n",
    "                \"q\": search_place\n",
    "            }\n",
    "\n",
    "            response = s.get(url, headers=headers, params=params)\n",
    "            soup = BeautifulSoup(response.text, 'html.parser')\n",
    "        myspan = soup.find_all(\"span\", {\"class\": \"Aq14fc\"})\n",
    "        if myspan != []:\n",
    "            print(float(myspan[0].text.replace(',','.')))\n",
    "            print(index)\n",
    "            print()\n",
    "            df_search_google['Rating'][index] = float(myspan[0].text.replace(',','.'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Сохраним датафрейм в новый датасет"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_search_google.to_csv('eating_with_ratings.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "\n",
    "\n",
    "def get_google_img(query):\n",
    "    \"\"\"\n",
    "    gets a link to the first google image search result\n",
    "    :param query: search query string\n",
    "    :result: url string to first result\n",
    "    \"\"\"\n",
    "    url = \"https://www.google.com/search?q=\" + str(query) + \"&source=lnms&tbm=isch\"\n",
    "    headers={'User-Agent':\"Mozilla/5.0 (Windows NT 6.1; WOW64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/43.0.2357.134 Safari/537.36\"}\n",
    "\n",
    "    html = requests.get(url, headers=headers).text\n",
    "\n",
    "    soup = BeautifulSoup(html, 'html.parser')\n",
    "    print(soup)\n",
    "    image = soup.find(\"img\",{\"class\":\"t0fcAb\"})\n",
    "    print(image)\n",
    "    if not image:\n",
    "        return \n",
    "    return image['src']\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    query = \"хачапури\"\n",
    "    print(get_google_img(query) or \"no image found\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Тестирование отрисовки пути из одной точки в другую через osmnx and networkx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import osmnx as ox\n",
    "import networkx as nx\n",
    "\n",
    "ox.config(log_console=True, use_cache=True)\n",
    "\n",
    "start_latlng = (55.7765825, 37.6758596)\n",
    "end_latlng = (55.776655763415, 37.674832)\n",
    "\n",
    "place = 'Moscow, Russia'\n",
    "\n",
    "mode = 'walk'\n",
    "optimizer = 'time'\n",
    "\n",
    "graph = ox.graph_from_place(place, network_type = mode)\n",
    "orig_node = ox.get_nearest_node(graph, start_latlng)\n",
    "dest_node = ox.get_nearest_node(graph, end_latlng)\n",
    "shortest_route = nx.shortest_path(graph, orig_node,dest_node,\n",
    "                                  weight=optimizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "shortest_route_map = ox.plot_route_folium(graph, shortest_route, \n",
    "                                          tiles='openstreetmap')\n",
    "shortest_route_map"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Тестирование \"определение координат по адресу\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "entry = \"https://nominatim.openstreetmap.org/search\"\n",
    "params = {\n",
    "    'q': 'Москва, пушкинская, 7',\n",
    "    'format': 'json',\n",
    "    'polygon': 1,\n",
    "    'addressdetails':1\n",
    "}\n",
    "r = requests.get(entry, params=params)\n",
    "(r.json()[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Был скачен ao.geojson - геоданные об округах Москвы"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import geopandas as gpd\n",
    "df_geo = gpd.read_file('ao.geojson')\n",
    "df_geo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_geo.insert(df_geo.shape[1], 'centroid', df_geo.geometry.centroid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m = folium.Map(location=[55.751999, 37.617734], zoom_start=12)\n",
    "\n",
    "for _, r in df_geo.iterrows():\n",
    "    sim_geo = gpd.GeoSeries(r['geometry']).simplify(tolerance=0.001)\n",
    "    geo_j = sim_geo.to_json()\n",
    "    geo_j = folium.GeoJson(data=geo_j,\n",
    "                           style_function=lambda x: {'fillColor': 'yellow'})\n",
    "    folium.Popup(r['NAME']).add_to(geo_j)\n",
    "    geo_j.add_to(m)\n",
    "    \n",
    "for _, r in df_geo.iterrows():\n",
    "    lat = r['centroid'].y\n",
    "    lon = r['centroid'].x\n",
    "    folium.Marker(location=[lat, lon],\n",
    "                  popup='Округ: {}'.format(r['NAME'])).add_to(m)\n",
    "\n",
    "m"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Спарсим таблицу с доп информацией об округах Москвы с вики"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wikiurl = \"https://ru.wikipedia.org/wiki/%D0%90%D0%B4%D0%BC%D0%B8%D0%BD%D0%B8%D1%81%D1%82%D1%80%D0%B0%D1%82%D0%B8%D0%B2%D0%BD%D0%BE-%D1%82%D0%B5%D1%80%D1%80%D0%B8%D1%82%D0%BE%D1%80%D0%B8%D0%B0%D0%BB%D1%8C%D0%BD%D0%BE%D0%B5_%D0%B4%D0%B5%D0%BB%D0%B5%D0%BD%D0%B8%D0%B5_%D0%9C%D0%BE%D1%81%D0%BA%D0%B2%D1%8B\"\n",
    "table_class = \"standard sortable jquery-tablesorter\"\n",
    "response = requests.get(wikiurl)\n",
    "print(response.status_code)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "soup = BeautifulSoup(response.text, 'html.parser')\n",
    "wiki_res = soup.find('table',{'class':\"standard\"})\n",
    "wiki_res"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Составляем новый датафрейм из таблицы вики"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "links = wiki_res.findAll('a')\n",
    "clear_links = [link.text for link in links if 'title' in link.attrs]\n",
    "df_okrug = pd.DataFrame()\n",
    "df_okrug['Okrug'] = clear_links\n",
    "df_okrug"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rows = indiatable.findAll(\"tr\")\n",
    "wiki_res = []\n",
    "for row in rows[1:]:\n",
    "    data = [d.text.rstrip() for d in row.find_all('td')]\n",
    "    wiki_res.append(data)\n",
    "\n",
    "header = [th.text.rstrip() for th in rows[0].find_all('th')][1:]\n",
    "header"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_1 = []\n",
    "for row in rows[1:]:\n",
    "    data = [d.text.rstrip() for d in row.select('td')]\n",
    "    data_1.append(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_1 = pd.DataFrame(data_1, columns=header)\n",
    "df_copy = data_1.copy()\n",
    "df_copy.head(13)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_copy = df_copy[:-1]\n",
    "df_copy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Итоговый датафрейм спарсенный с вики"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "moscow_data = pd.concat([df_okrug, df_copy], axis=1)\n",
    "moscow_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "moscow_data.to_csv('moscow.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.4 ('ox')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "3f13e2157a92ed9dc4f3afcbc7be07ac3e23cd9c3d01c6dd72339e72800fb0fb"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
